# Big O Notation

A way to categorize the time or memory of an algorithm based on input.
Generalizes the growth of an algorithm.

It's _not_ an exact measurement.
Will _not_ determine how many CPU cycles it takes.
